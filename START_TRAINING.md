# Full-Scale Training - Ready to Use!

## ‚úÖ System Status: READY

All components are working correctly:
- ‚úÖ Model architecture implemented correctly
- ‚úÖ Data loading working (600 players)
- ‚úÖ Training loop functional
- ‚úÖ GPU acceleration enabled
- ‚úÖ Checkpointing working
- ‚úÖ Training scripts created

## Quick Start Commands

### 1. Test Run (2 minutes - verify everything works)
```bash
cd /home/cthsu/Workspace/ML_2025/HW2/Q5
conda run -n ml_hw2 python train_full_scale.py --preset test --epochs 2
```

### 2. Medium Training (8-12 hours - recommended)
```bash
cd /home/cthsu/Workspace/ML_2025/HW2/Q5

# Run in background
nohup conda run -n ml_hw2 python train_full_scale.py --preset medium > training_medium.log 2>&1 &

# Monitor progress
tail -f training_medium.log
```

### 3. Large Training (24-48 hours - best accuracy)
```bash
cd /home/cthsu/Workspace/ML_2025/HW2/Q5

# Run in background
nohup conda run -n ml_hw2 python train_full_scale.py --preset large > training_large.log 2>&1 &

# Monitor progress  
tail -f training_large.log

# Check GPU usage
watch -n 1 nvidia-smi
```

## Training Scripts Available

### 1. Python Script (Recommended)
**File**: `train_full_scale.py`

**Features**:
- Multiple presets (test, small, medium, large)
- Resume capability
- Auto-configuration
- Parameter estimation

**Usage**:
```bash
# Basic
conda run -n ml_hw2 python train_full_scale.py --preset medium

# With options
conda run -n ml_hw2 python train_full_scale.py \
    --preset large \
    --epochs 100 \
    --batch_size 16 \
    --output_dir models/my_training

# Resume from checkpoint
conda run -n ml_hw2 python train_full_scale.py \
    --preset medium \
    --resume models/full_training_medium/checkpoint_epoch_30.pth
```

### 2. Bash Script (Alternative)
**File**: `train_full.sh`

**Usage**:
```bash
# After activating conda
conda activate ml_hw2
./train_full.sh medium
```

### 3. Direct Call (Maximum Control)
**File**: `train_style_model.py`

**Usage**:
```bash
conda run -n ml_hw2 python train_style_model.py \
    --train_dir test_set/query_set \
    --epochs 50 \
    --batch_size 16 \
    --num_samples 1000 \
    --hidden_channels 128 \
    --num_blocks 3 \
    --move_embed_dim 128 \
    --num_heads 8 \
    --num_transformer_layers 3 \
    --style_embed_dim 256 \
    --max_moves 75 \
    --output_dir models/custom \
    --num_workers 4 \
    --save_interval 5
```

## Configuration Presets Comparison

| Preset | Params | Time | GPU Mem | Epochs | Accuracy |
|--------|--------|------|---------|--------|----------|
| test   | 280K   | 5min | 2GB     | 5      | Low      |
| small  | 500K   | 3hr  | 6GB     | 50     | Good     |
| medium | 2M     | 10hr | 10GB    | 50     | Very Good|
| large  | 9M     | 40hr | 14GB    | 100    | Best     |

## Model Architecture (Correctly Implemented)

```
Input: (batch, seq_len, 18, 19, 19)
  ‚Üì
[Stage 1: Per-Move Encoding]
  Conv(18‚Üíchannels) 
  ‚Üì
  ResidualBlock √ó num_blocks
  ‚Üì
  GlobalAvgPool
  ‚Üì
  MLP ‚Üí move_embed_dim
  ‚Üì
Output: (batch, seq_len, move_embed_dim)
  ‚Üì
[Stage 2: Game-Level Aggregation]
  PositionalEncoding
  ‚Üì
  TransformerEncoder √ó num_layers
  ‚Üì
  MeanPooling (over sequence)
  ‚Üì
  MLP ‚Üí style_embed_dim
  ‚Üì
  Tanh
  ‚Üì
  L2 Normalize
  ‚Üì
Final Output: (batch, style_embed_dim) [normalized to unit length]
```

## Expected Training Behavior

### Loss Progression
```
Epoch 1:  ~1.0-1.5  (random)
Epoch 10: ~0.7-0.9  (learning)
Epoch 25: ~0.5-0.7  (improving)
Epoch 50: ~0.3-0.5  (converged)
Epoch 100: ~0.2-0.3 (well-trained)
```

### Training Output Example
```
======================================================================
Go Style Detection - Full-scale Training
======================================================================

Preset: medium

Data:
  Training directory: test_set/query_set
  Output directory: models/full_training_medium

Training Parameters:
  Epochs: 50
  Batch size: 16
  Samples per epoch: 1000
  Max moves per game: 75

Model Architecture:
  Hidden channels: 128
  Residual blocks: 3
  Move embedding dim: 128
  Transformer heads: 8
  Transformer layers: 3
  Style embedding dim: 256
  Estimated parameters: ~2.00M

System:
  Workers: 4
  Save interval: 5 epochs
  Device: CUDA
  GPU: NVIDIA GeForce RTX 5070 Ti
  GPU Memory: 16.0 GB
======================================================================

Loading SGF files from test_set/query_set...
  Found 600 SGF files
Loading SGF files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 600/600 [00:10<00:00, 58.43it/s]
Loaded dataset:
  - Players: 600
  - Will generate 1000 random samples per epoch

Creating model...
Model parameters: 2,034,560

Starting training for 50 epochs...
Epoch 1/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:52<00:00,  1.21it/s, loss=0.834]

Epoch 1/50 - Average Loss: 1.0234
‚úì Saved best model (loss: 1.0234)
‚úì Saved checkpoint at epoch 1

Epoch 2/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:51<00:00,  1.23it/s, loss=0.723]

Epoch 2/50 - Average Loss: 0.8156
‚úì Saved best model (loss: 0.8156)
...
```

## Monitoring Training

### Check Progress
```bash
# View log file
tail -f training_medium.log

# Check GPU usage
nvidia-smi

# Check process
ps aux | grep train_style_model
```

### Check Saved Models
```bash
ls -lh models/full_training_medium/

# Should see:
# - best_model.pth (best model so far)
# - checkpoint_epoch_5.pth, checkpoint_epoch_10.pth, etc.
# - training_config.json
# - full_training_config.json
```

## After Training

### 1. Verify Training Completed
```bash
# Check if best_model.pth exists
ls -lh models/full_training_medium/best_model.pth

# View final configuration
cat models/full_training_medium/training_config.json
```

### 2. Test Inference (Next Step)
After training completes, update `infer_style.py` with the same data loading fixes, then:

```bash
conda run -n ml_hw2 python infer_style.py \
    --model_path models/full_training_medium/best_model.pth \
    --query_dir test_set/query_set \
    --candidate_dir test_set/cand_set \
    --output_file predictions.csv \
    --max_moves 75
```

## Troubleshooting

### If training fails to start
```bash
# Check conda environment
conda activate ml_hw2
python -c "import torch; print(torch.__version__)"

# Check directory
cd /home/cthsu/Workspace/ML_2025/HW2/Q5
ls -lh train_full_scale.py
```

### If out of memory
```bash
# Reduce batch size
conda run -n ml_hw2 python train_full_scale.py \
    --preset medium \
    --batch_size 8  # Instead of 16
```

### If training is too slow
```bash
# Use smaller model
conda run -n ml_hw2 python train_full_scale.py --preset small

# Or reduce max_moves
conda run -n ml_hw2 python train_full_scale.py \
    --preset medium \
    --max_moves 50  # Instead of 75
```

## Recommended Training Schedule

### Day 1: Verification
```bash
# Quick test (5 minutes)
conda run -n ml_hw2 python train_full_scale.py --preset test --epochs 2

# Small test (2-3 hours)
conda run -n ml_hw2 python train_full_scale.py --preset small --epochs 20
```

### Day 2-3: Production Training
```bash
# Medium configuration (overnight)
nohup conda run -n ml_hw2 python train_full_scale.py --preset medium > medium.log 2>&1 &
```

### Optional: Best Model
```bash
# Large configuration (1-2 days)
nohup conda run -n ml_hw2 python train_full_scale.py --preset large > large.log 2>&1 &
```

## Files Created

1. **train_full_scale.py** - Main training script with presets
2. **train_full.sh** - Bash wrapper script
3. **FULL_TRAINING_GUIDE.md** - Detailed usage guide
4. **THIS_FILE** - Quick reference

## Next Steps

1. ‚úÖ Choose preset (recommend: **medium**)
2. ‚úÖ Start training with command above
3. ‚è≥ Wait for training (monitor with `tail -f`)
4. ‚è≥ Update `infer_style.py` (apply same data loading fixes)
5. ‚è≥ Run inference and generate predictions

**You're all set to start full-scale training!** üöÄ
